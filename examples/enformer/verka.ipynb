{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buzun/filtered-transformer/.conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import EnformerDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = EnformerDataset(\"/mnt/nfs_dna/DNALM/downstream_tasks/enformer/human/h5/human_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGTGAGAGCA[CLS]CCCATTGTTT[CLS]CTGCTGGTTA[CLS]CCCTCATGCG[CLS]AGATTTTTGT[CLS]TTGCTTCCTT[CLS]TCTCTCCCCA[CLS]GATACTTCTG[CLS]TTACTACTTC[CLS]ACTACTGTGG[CLS]GGAACTTCAC[CLS]AAAAATGCAT[CLS]CCCTCAGCAC[CLS]CCTGGGCTCT[CLS]GTGTCTGAAC[CLS]CACTTCACAT[CLS]GCCTTCTGTA[CLS]CTGCATCCCA[CLS]GCACTCCAGT[CLS]ATTCCTGAGC[CLS]TGAAATCTCA[CLS]GACCTCGTAA[CLS]TTACCAATCA[CLS]CTGTGCTTTT[CLS]GACACCCACC[CLS]CCTGCCACTC[CLS]ACTACCAGCT[CLS]TCTCTTATTT[CLS]TTCAACTTAT[CLS]TCTGGTTCAC[CLS]CAACGAAAAC[CLS]GATTCTTCAA[CLS]GCCCACTGGG[CLS]GCCTCAATCC[CLS]ATGTATTCAT[CLS]TATTGGCTGC[CLS]TCTCGTGAGG[CLS]TCAGATCTCT[CLS]TTTGTTTTTA[CLS]CTCATCTTAG[CLS]ATGTCATAGA[CLS]CTATCATGTG[CLS]CCCCTAGCTT[CLS]TCTTTGTTGT[CLS]ATTTGCCTTT[CLS]AAAGGTTTCA[CLS]ACCTTGCTCA[CLS]GATTTAACTC[CLS]TTCAACTGCT[CLS]CCCCACTTAT[CLS]TCCTGTGTGG[CLS]ATGAATGTGG[CLS]CTAGAGAAAA[CLS]ATGCACAAAC[CLS]ATGATGACAA[CLS]ATTTATGATC[CLS]ACAAATCCCA[CLS]AGTAAGCCTC[CLS]AACACCACTA[CLS]GGCCATTCTA[CLS]CTCTATGGCT[CLS]TTATTCAGTT[CLS]CCCAATGCCT[CLS]CATTCCACCC[CLS]CAAATTTTAA[CLS]GAAGATAATT[CLS]TCATCTCTTT[CLS]TCAAAATTTC[CLS]CAAAGTATTT[CLS]CCTCTTATTC[CLS]TTTTTAAGGC[CLS]AAACTCATCC[CLS]ATATTAACAG[CLS]TAGACAAAAC[CLS]ATGAGTTCAA[CLS]AAAAAAATTA[CLS]TTAAGAATTT[CLS]CAAGACTGTG[CLS]ATAGCAGGAC[CLS]ATTACGCTAA[CLS]GGGTGAGCCC[CLS]CATCTGAACA[CLS]CAGGGCCTTG[CLS]TGTGACTGCA[CLS]CTGGCTACAG[CLS]GCCTGCTCAG[CLS]CTGGCCCTGC[CLS]TCAGGATCAC[CLS]ACCTTAGACA[CLS]GGAGACAAGG[CLS]GAAATCCAGC[CLS]TCCTCTTCAG[CLS]GGGTTGGCAG[CLS]CACTGATGCA[CLS]GTCGATTCCT[CLS]TTGTTTTCTG[CLS]CATATTGGGA[CLS]CACAGTGCAG[CLS]GTTACTTGAG[CLS]CCCAGTTCAA'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "seq, tg, coo = next(iter(train_loader))\n",
    "tokenizer = AutoTokenizer.from_pretrained('AIRI-Institute/gena-lm-bert-base')\n",
    "s =  \"[CLS]\".join([seq[0][i * 10: i * 10 + 10] for i in range(100)])\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "s =  \"[SEP]\".join([seq[0][i * 10: i * 10 + 10] for i in range(100)])\n",
    "tokens = torch.tensor(tokenizer(s)[\"input_ids\"])\n",
    "tokens[tokens == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") \n",
    "from collections import namedtuple\n",
    "from typing import Tuple, Optional\n",
    "from torch import Tensor\n",
    "from common_modules.transformers import BertRecurrentTransformerWithTokenizer\n",
    "from memup.base import MemUpMemory, State, DataCollectorReplace, MemoryOut, DataCollectorAppend\n",
    "from memup.loss import TS\n",
    "\n",
    "DataType = namedtuple(\"DataType\", [\"text\", \"target\", \"length\"])\n",
    "\n",
    "\n",
    "class MemUpMemoryImpl(MemUpMemory[DataType]):\n",
    "\n",
    "    def __init__(self, mem_tr: BertRecurrentTransformerWithTokenizer):\n",
    "        super().__init__()\n",
    "        self.mem_tr = mem_tr\n",
    "\n",
    "    def forward(self, data: DataType, state: State) -> Tuple[Optional[Tensor], State]:\n",
    "        os = self.mem_tr.forward(data.text, state)\n",
    "        return None, os.state\n",
    "\n",
    "\n",
    "class DataCollectorTrain(DataCollectorAppend[DataType, TS]):\n",
    "    def apply(self, data: DataType, out: MemoryOut, state: State) -> TS:\n",
    "        return TS(data.target, state)\n",
    "\n",
    "\n",
    "class DataCollectorLastState(DataCollectorReplace[DataType, TS]):\n",
    "    def apply(self, data: DataType, out: MemoryOut, state: State) -> TS:\n",
    "        return TS(data.target, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from data_filters.sliding_window import SlidingWindowFilterTuple\n",
    "from memup.loss import PredictorLoss, LossModule, PredictorLossStateOnly, EvalLossStateOnly\n",
    "from memup.preproc import IncrementStep\n",
    "from common_modules.transformers import BertRecurrentTransformerWithTokenizer, BertRecurrentTransformer, RecurrentTransformerFromBert, \\\n",
    "    BertRecurrentTransformerWithTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from memup.base import MemoryRollout\n",
    "import torch\n",
    "\n",
    "\n",
    "rollout = 800\n",
    "state_length = 50\n",
    "torch.cuda.set_device(\"cuda:1\")\n",
    "data_filter = SlidingWindowFilterTuple[DataType](rollout, pad_fields={\"text\"}, padding=200, skip_fields={\"target\", \"length\"})\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('AIRI-Institute/gena-lm-bert-base')\n",
    "bert: BertModel = BertModel.from_pretrained('AIRI-Institute/gena-lm-bert-base')\n",
    "bert.train()\n",
    "mem_transformer = BertRecurrentTransformerWithTokenizer(bert, tokenizer, 270, 4, 4, bert.config.hidden_size * 2).cuda()\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = RecurrentTransformerFromBert(bert, 4, 4, bert.config.hidden_size * 2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(bert.config.hidden_size, bert.config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert.config.hidden_size, bert.config.hidden_size),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert.config.hidden_size, 5313)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        out = self.encoder.forward(x, state).out\n",
    "        return self.head(out).abs()\n",
    "\n",
    "\n",
    "predictor = Predictor().cuda()\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam([\n",
    "    {\"params\": mem_transformer.bert.parameters(), \"lr\": 4e-6},\n",
    "    {\"params\": predictor.parameters(), \"lr\": 2e-5},\n",
    "    {\"params\": mem_transformer.encoder.parameters(), \"lr\": 2e-5},\n",
    "])\n",
    "\n",
    "memup_iter = MemoryRollout[DataType](\n",
    "    steps=2,\n",
    "    memory=MemUpMemoryImpl(mem_transformer),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[IncrementStep()]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, target, coords = next(iter(train_loader))\n",
    "state = torch.zeros(target.shape[0], state_length, bert.config.hidden_size, device=torch.device(\"cuda\"))\n",
    "T = len(text[0])\n",
    "done = False\n",
    "info = {}\n",
    "\n",
    "while not done:\n",
    "    data_collector, state, info, done = memup_iter.forward(DataType(text, target, T), state, info, DataCollectorTrain())\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b20f3d5c387d4ae708cf3b110b498b9508be8d8f3c9e0454b8d051d60f269555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
