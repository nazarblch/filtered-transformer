{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from gena_lm.modeling_bert import BertModel, BertForSequenceClassification\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from data_filters.sliding_window import SlidingWindowFilterTuple\n",
    "from data_filters.top_errors import TopErrorsFilter, InputTarget\n",
    "from modules import Predictor, DataType, MemUpMemoryImpl, TailAccuracyMetric, \\\n",
    "    DataCollectorEval, DataCollectorEvalWithState, DataCollectorTrain\n",
    "from data import CopyTask\n",
    "from memup.accumulator import Accumulator\n",
    "from memup.base import SeqDataFilter, MemUpMemory, MemUpLoss, State, Info, Done, InfoUpdate, \\\n",
    "    MemoryRolloutWithLoss, MemoryRollout, DataCollector, SD, MemoryOut, CT, DataCollectorAppend\n",
    "from memup.loss import PredictorLossWithContext, LossModule, EvalLoss, TOS, PT, PredictorLoss\n",
    "from memup.preproc import ContextPreprocessor, NStepUpdate, IncrementStep, ErrorPreprocessor, TargetsSampler, \\\n",
    "    TailTargets, select_by_index\n",
    "from metrics.accuracy import AccuracyMetric\n",
    "from metrics.base import Metric\n",
    "from metrics.pearson import PearsonCorrLoss, PearsonCorrMetric\n",
    "from common_modules.pos_encoding import EmbedWithPos\n",
    "from common_modules.transformers import BertRecurrentTransformer, RecurrentTransformerFromBert, \\\n",
    "    BertRecurrentTransformerWithTokenizer, TorchRecurrentTransformer, TorchRecurrentNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mem_transformer = TorchRecurrentTransformer(128, 4, 3, 512, dropout=0.1).cuda()\n",
    "embed = EmbedWithPos(10, 128, 5.0).cuda()\n",
    "predictor = Predictor().cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq_length = 500\n",
    "rollout = 50\n",
    "state_length = 20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CopyTask(10000, 10, seq_length), shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(CopyTask(1000, 10, seq_length), shuffle=False, batch_size=250)\n",
    "\n",
    "opt = torch.optim.Adam([\n",
    "    {\"params\": mem_transformer.parameters(), \"lr\": 5e-5},\n",
    "    {\"params\": embed.parameters(), \"lr\": 5e-5},\n",
    "    {\"params\": predictor.parameters(), \"lr\": 5e-5}\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mem_acc = Accumulator(mem_transformer, decay=0.9)\n",
    "pred_acc = Accumulator(predictor, decay=0.9)\n",
    "embed_acc = Accumulator(embed, decay=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_filter = SlidingWindowFilterTuple[DataType](rollout, padding=0, skip_fields={\"length\"})\n",
    "errors_filter = TopErrorsFilter(rollout, (10, 10), pred_acc, nn.CrossEntropyLoss(reduction=\"none\"), is_random=False)\n",
    "\n",
    "memup_iter = MemoryRollout[DataType](\n",
    "    steps=2,\n",
    "    memory=MemUpMemoryImpl(embed, mem_transformer),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[\n",
    "        IncrementStep(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "memup_iter_acc = MemoryRollout[DataType](\n",
    "    steps=1000,\n",
    "    memory=MemUpMemoryImpl(embed_acc.get_module(), mem_acc.get_module()),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[\n",
    "        IncrementStep(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "memup_iter_eval = MemoryRolloutWithLoss[DataType, PT](\n",
    "    steps=1000,\n",
    "    memory=MemUpMemoryImpl(embed, mem_transformer),\n",
    "    loss=EvalLoss([TailAccuracyMetric()]),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[\n",
    "        IncrementStep()\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(i):\n",
    "\n",
    "    print(\"evaluate\")\n",
    "    mem_transformer.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        state2 = torch.zeros(x.shape[0], state_length, 128).cuda()\n",
    "\n",
    "        _, last_state, info, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state2, {}, DataCollectorEval(predictor))\n",
    "        _, _, info2, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state2, {}, DataCollectorEvalWithState(predictor, last_state))\n",
    "\n",
    "        print(info2[\"metrics\"])\n",
    "\n",
    "    mem_transformer.train()\n",
    "    predictor.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ContextCollector(DataCollectorAppend[DataType, Tensor]):\n",
    "\n",
    "    def apply(self, data: SD, out: MemoryOut, state: State) -> CT:\n",
    "        return out.cpu()\n",
    "\n",
    "\n",
    "predictor_loss = PredictorLossWithContext(predictor, [\n",
    "        LossModule(nn.CrossEntropyLoss(), \"CE\", 1.0),\n",
    "        LossModule(AccuracyMetric(), \"TAcc\", 0.0)\n",
    "], cur_step_loss_coef=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(\"epoch\", i)\n",
    "    eval(i)\n",
    "\n",
    "    last_info = {}\n",
    "\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        state = torch.zeros(x.shape[0], state_length, 128).cuda()\n",
    "        T = x.shape[1]\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, last_state, _, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state, {}, DataCollectorEval(predictor))\n",
    "            _, _, info2, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state, {},\n",
    "                                                     DataCollectorEvalWithState(predictor, last_state))\n",
    "            print(\"train eval\", info2[\"metrics\"])\n",
    "\n",
    "        context_collector, last_state, _, _ = memup_iter_acc.forward(DataType(x, y, T), state, {}, ContextCollector())\n",
    "        context = torch.cat(context_collector.collection, 1)\n",
    "        selected_data, _ = errors_filter.forward(InputTarget(context, y, T), last_state, {})\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            data_collector, state, info, done = memup_iter.forward(DataType(x, y, T), state, info, DataCollectorTrain())\n",
    "            loss = predictor_loss.forward(data_collector, info, selected_data)\n",
    "            last_info = info[\"losses\"]\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        mem_acc.accumulate()\n",
    "        pred_acc.accumulate()\n",
    "        embed_acc.accumulate()\n",
    "\n",
    "    print(last_info)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    print(last_info)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state = torch.zeros(x.shape[0], state_length, 128).cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memup_iter_eval = MemoryRolloutWithLoss[DataType, PT](\n",
    "    steps=1000,\n",
    "    memory=MemUpMemoryImpl(embed_acc.get_module(), mem_acc.get_module()),\n",
    "    loss=EvalLoss([TailAccuracyMetric()]),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[\n",
    "        IncrementStep()\n",
    "    ]\n",
    ")\n",
    "mem_transformer.eval()\n",
    "predictor.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, last_state, _, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state, {}, DataCollectorEval(predictor))\n",
    "    _, _, info2, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state, {},\n",
    "                                             DataCollectorEvalWithState(predictor, last_state))\n",
    "    print(\"train eval 1\", info2[\"metrics\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mem_acc.get_module().train()\n",
    "pred_acc.get_module().eval()\n",
    "\n",
    "for x, y in test_loader:\n",
    "    state2 = torch.zeros(x.shape[0], state_length, 128).cuda()\n",
    "\n",
    "    _, last_state, info, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state2, {}, DataCollectorEval(predictor))\n",
    "    _, _, info2, _ = memup_iter_eval.forward(DataType(x, y, x.shape[1]), state2, {}, DataCollectorEvalWithState(predictor, last_state))\n",
    "\n",
    "    print(info[\"metrics\"], info2[\"metrics\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
