{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"/home/jovyan/mlenv/bin/python\" требуется пакет ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/jovyan/mlenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"/home/jovyan/mlenv/bin/python\" требуется пакет ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/jovyan/mlenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from typing import Dict\n",
    "sys.path.append(\"/home/jovyan/filtered-transformer/\")\n",
    "\n",
    "from data_filters.top_errors import InputTarget, TopErrorsFilter\n",
    "from memup.accumulator import Accumulator\n",
    "from metrics.pearson import MeanPearsonCorrCoefPerChannel, PearsonCorrLoss\n",
    "from torch import Tensor, nn\n",
    "from memup.loss import LossModule, PredictorLoss, PredictorLossWithContext\n",
    "from memup.base import CT, SD, DataCollectorAppend, MemoryOut, MemoryRollout, State\n",
    "from memup.preproc import IncrementStep\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, HfArgumentParser\n",
    "from transformers.optimization import AdamW\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from examples.enformer_2.data import EnformerDataset\n",
    "from examples.enformer_2.modules import BertForEnformer, DataCollectorTrain, DataFilter, MemUpMemoryImpl, Predictor\n",
    "from gena_lm.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "torch.cuda.set_device(\"cuda:0\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('AIRI-Institute/gena-lm-bert-base')\n",
    "model_cfg = AutoConfig.from_pretrained('AIRI-Institute/gena-lm-bert-base')\n",
    "model_cfg.num_labels = EnformerDataset.TG_COUNT\n",
    "model = BertForEnformer(config=model_cfg)\n",
    "\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "predictor = Predictor(model_cfg).cuda()\n",
    "predictor.eval()\n",
    "\n",
    "weights = torch.load(\"/home/jovyan/enformer.pt\", map_location=\"cpu\")\n",
    "model.load_state_dict(weights[\"mem_acc\"])\n",
    "predictor.load_state_dict(weights[\"pred_acc\"])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    pad_token_ids = {'input_ids': tokenizer.pad_token_id, 'token_type_ids': 0, 'attention_mask': 0, 'bins_mask': 0, 'labels': 0}\n",
    "\n",
    "    def pad_batch(name, feature_keys):\n",
    "\n",
    "        padded_batch = {k: [] for k in feature_keys}\n",
    "        \n",
    "        for k in feature_keys:\n",
    "            padded_batch[k] = pad_sequence(\n",
    "                [torch.from_numpy(el[name][k]) for el in batch], \n",
    "                batch_first=True, \n",
    "                padding_value=pad_token_ids[k]\n",
    "            )\n",
    "\n",
    "        return padded_batch\n",
    "\n",
    "    padded_center = pad_batch(\"center\", ['input_ids', 'token_type_ids', 'attention_mask', 'bins_mask'])\n",
    "    padded_center['labels'] = torch.stack([torch.from_numpy(el[\"center\"][\"labels\"]) for el in batch])\n",
    "\n",
    "    padded_left = pad_batch(\"left\", ['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "    padded_right = pad_batch(\"right\", ['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "\n",
    "    return {\n",
    "        \"left\": padded_left,\n",
    "        \"center\": padded_center,\n",
    "        \"right\": padded_right\n",
    "    }\n",
    "\n",
    "\n",
    "data_filter = DataFilter(14, 300)\n",
    "\n",
    "class ContextCollector(DataCollectorAppend[Dict[str, Tensor], Tensor]):\n",
    "\n",
    "    def apply(self, data: SD, out: MemoryOut, state: State) -> CT:\n",
    "        return out.cpu() if out is not None else None\n",
    "\n",
    "mem_acc = Accumulator(model, decay=0.9)\n",
    "pred_acc = Accumulator(predictor, decay=0.9)\n",
    "\n",
    "errors_filter = TopErrorsFilter(14, (14, 14), pred_acc, nn.PoissonNLLLoss(log_input=False, reduction=\"none\"), is_random=True)\n",
    "\n",
    "memup_iter_acc = MemoryRollout[Dict[str, torch.Tensor]](\n",
    "    steps=1000,\n",
    "    memory=MemUpMemoryImpl(mem_acc),\n",
    "    data_filter=data_filter,\n",
    "    info_update=[IncrementStep()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 34012\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.6783071160316467 -0.5552586317062378\n",
      "0.7053796052932739 -0.540067732334137\n",
      "0.6897053718566895 -0.5507819056510925\n",
      "0.6714479327201843 -0.5676361322402954\n",
      "0.7063537240028381 -0.5597556829452515\n",
      "0.6333743333816528 -0.5462321639060974\n",
      "0.6811623573303223 -0.5505009293556213\n",
      "0.6368356943130493 -0.5733550786972046\n",
      "0.6317087411880493 -0.5485631227493286\n",
      "0.6617066264152527 -0.5710166096687317\n",
      "0.7001914978027344 -0.5541484355926514\n",
      "0.5223304033279419 -0.5695292949676514\n",
      "0.6826533675193787 -0.5671328902244568\n",
      "0.6664441823959351 -0.5565056800842285\n",
      "0.6912162899971008 -0.5757006406784058\n",
      "0.6986082792282104 -0.5586433410644531\n",
      "0.697401762008667 -0.5637553930282593\n",
      "0.6868051886558533 -0.561008632183075\n",
      "0.6852378845214844 -0.5736974477767944\n",
      "0.6650139689445496 -0.5729855298995972\n",
      "0.6717947721481323 -0.5745871067047119\n",
      "0.6764571666717529 -0.5581704378128052\n",
      "0.6846470832824707 -0.5719487071037292\n",
      "0.653254508972168 -0.5695027112960815\n",
      "0.6278414130210876 -0.5756451487541199\n",
      "0.6760780811309814 -0.5738592147827148\n",
      "0.683779776096344 -0.5587814450263977\n",
      "0.6570159792900085 -0.5457411408424377\n",
      "0.6844868063926697 -0.5569821000099182\n",
      "0.6509803533554077 -0.5475805401802063\n",
      "0.5999483466148376 -0.5517359375953674\n",
      "0.551505446434021 -0.5893452167510986\n",
      "0.544457733631134 -0.56924968957901\n",
      "0.6338832974433899 -0.5530966520309448\n",
      "0.6454035639762878 -0.5446531176567078\n",
      "0.6626495718955994 -0.5634298324584961\n",
      "0.684866726398468 -0.5520660281181335\n",
      "0.6257241368293762 -0.553040623664856\n",
      "0.6756497621536255 -0.5773710012435913\n",
      "0.6288663148880005 -0.5799778699874878\n",
      "0.7028369903564453 -0.5457290410995483\n",
      "0.665743350982666 -0.5623093843460083\n",
      "0.7015442252159119 -0.5489389896392822\n",
      "0.6616118550300598 -0.5596809387207031\n",
      "0.6684139370918274 -0.5533729791641235\n",
      "0.644096314907074 -0.5543416142463684\n",
      "0.671199381351471 -0.5823961496353149\n",
      "0.6117066740989685 -0.5745903253555298\n",
      "0.5945310592651367 -0.5554788708686829\n",
      "0.6509402990341187 -0.5464950203895569\n",
      "0.661950409412384 -0.5333993434906006\n",
      "0.6698163747787476 -0.5513885617256165\n",
      "0.6305922865867615 -0.5624849200248718\n",
      "0.6821942925453186 -0.5570423603057861\n",
      "0.6349121928215027 -0.5682645440101624\n",
      "0.6336442232131958 -0.5825058817863464\n",
      "0.649502694606781 -0.5431382060050964\n",
      "0.6385181546211243 -0.5360324382781982\n",
      "0.6069000959396362 -0.5402761697769165\n",
      "0.5983511209487915 -0.5530279874801636\n",
      "0.5563818216323853 -0.5611875057220459\n",
      "0.25522324442863464 -0.5516895651817322\n",
      "0.6161291003227234 -0.5479812622070312\n",
      "0.5578137040138245 -0.5396084785461426\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "-0.20467527210712433 -0.5732983350753784\n",
      "-0.1955733448266983 -0.5628525018692017\n",
      "0.6256101131439209 -0.49035465717315674\n",
      "0.6875731348991394 -0.5512866377830505\n",
      "0.6728765368461609 -0.5478953719139099\n",
      "0.6951366662979126 -0.5236983299255371\n",
      "0.6738782525062561 -0.5624785423278809\n",
      "0.6610605120658875 -0.5605452656745911\n",
      "0.6411834359169006 -0.5530869364738464\n",
      "0.6524928212165833 -0.5576112866401672\n",
      "-0.18279318511486053 -0.5419030785560608\n",
      "0.31649622321128845 -0.5590302348136902\n",
      "0.6509220600128174 -0.5201815962791443\n",
      "0.6802245378494263 -0.5289806127548218\n",
      "0.6711270809173584 -0.5413303971290588\n",
      "0.6772621870040894 -0.55840665102005\n",
      "0.5185292959213257 -0.5552011728286743\n",
      "0.6666588187217712 -0.5444161891937256\n",
      "0.6749542951583862 -0.5803390145301819\n",
      "0.693996250629425 -0.5500526428222656\n",
      "0.6861276030540466 -0.5552482604980469\n",
      "0.6769452691078186 -0.5531268119812012\n",
      "0.6601892113685608 -0.5517024397850037\n",
      "0.6556203365325928 -0.5334691405296326\n",
      "0.40457597374916077 -0.5419344305992126\n",
      "0.6425840854644775 -0.5339217782020569\n",
      "0.6427680850028992 -0.5628217458724976\n",
      "0.6394036412239075 -0.5615613460540771\n",
      "0.6486456990242004 -0.5537340044975281\n",
      "0.6076220870018005 -0.542695164680481\n",
      "0.6582526564598083 -0.5633910298347473\n",
      "0.6568410992622375 -0.5669786334037781\n",
      "0.6539980173110962 -0.562367856502533\n",
      "0.6886711120605469 -0.5283514261245728\n",
      "0.6197211742401123 -0.5687742829322815\n",
      "-0.13980995118618011 -0.5667592883110046\n",
      "0.33033421635627747 -0.5861287713050842\n",
      "0.6889120936393738 -0.5464226603507996\n",
      "0.6679242253303528 -0.5282717347145081\n",
      "0.7002070546150208 -0.5162864923477173\n",
      "0.6769728660583496 -0.5413573980331421\n",
      "0.6749699115753174 -0.5438008904457092\n",
      "0.6924630999565125 -0.5492851734161377\n",
      "0.6677039861679077 -0.5664100050926208\n",
      "0.6748488545417786 -0.5650123357772827\n",
      "0.7002771496772766 -0.5461530685424805\n",
      "0.5746830105781555 -0.5295819044113159\n",
      "0.6264982223510742 -0.5229301452636719\n",
      "0.6524859666824341 -0.5317381024360657\n",
      "0.47066110372543335 -0.5243803262710571\n",
      "-0.03940346837043762 -0.5543738007545471\n",
      "0.42638885974884033 -0.5670047402381897\n",
      "0.5618419051170349 -0.542208731174469\n",
      "0.5833854079246521 -0.5431370139122009\n",
      "0.6485280394554138 -0.5457146763801575\n",
      "0.4355027973651886 -0.5520099401473999\n",
      "0.41002726554870605 -0.5386438965797424\n",
      "0.6487770676612854 -0.5705763697624207\n",
      "0.6180956363677979 -0.5665374398231506\n",
      "0.6654263734817505 -0.5526918768882751\n",
      "0.6752112507820129 -0.5616833567619324\n",
      "0.6837866902351379 -0.5350891351699829\n",
      "0.6735313534736633 -0.5500011444091797\n",
      "0.6785255074501038 -0.5605955123901367\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.6928091645240784 -0.5282899141311646\n",
      "0.6829848885536194 -0.5086678862571716\n",
      "0.6631582379341125 -0.5177463889122009\n",
      "0.4729210436344147 -0.5497816205024719\n",
      "0.6836363673210144 -0.5227156281471252\n",
      "0.5783132314682007 -0.5431214570999146\n",
      "0.40583157539367676 -0.5485659241676331\n",
      "0.5606828927993774 -0.5585764646530151\n",
      "0.5768318176269531 -0.5291531682014465\n",
      "0.6041333079338074 -0.5486717820167542\n",
      "0.5033616423606873 -0.5318953394889832\n",
      "0.608958899974823 -0.5392481684684753\n",
      "0.6405332088470459 -0.546310544013977\n",
      "0.6378002762794495 -0.5507959723472595\n",
      "0.5807762742042542 -0.554619312286377\n",
      "0.6696484088897705 -0.5582522749900818\n",
      "0.703673779964447 -0.5562289357185364\n",
      "-0.4446161985397339 -0.5646573901176453\n",
      "0.0975681021809578 -0.5685798525810242\n",
      "0.5926439762115479 -0.5645274519920349\n",
      "0.6329351663589478 -0.5566174983978271\n",
      "0.6121696829795837 -0.5443964600563049\n",
      "0.6369630694389343 -0.5536651611328125\n",
      "0.6455147862434387 -0.5800855159759521\n",
      "0.5752350091934204 -0.5849413275718689\n",
      "0.6485124230384827 -0.5760125517845154\n",
      "0.6526919007301331 -0.5439846515655518\n",
      "0.6510190367698669 -0.5499404668807983\n",
      "0.6057427525520325 -0.5583948493003845\n",
      "0.6365758776664734 -0.5491471290588379\n",
      "0.6382449865341187 -0.5292553305625916\n",
      "0.6470543742179871 -0.5259628891944885\n",
      "0.600284218788147 -0.5391766428947449\n",
      "0.6283366680145264 -0.535873293876648\n",
      "0.5123043060302734 -0.5609977841377258\n",
      "0.507623553276062 -0.5483413934707642\n",
      "0.6638029217720032 -0.5307051539421082\n",
      "0.6868116855621338 -0.5527151823043823\n",
      "0.6165400743484497 -0.5321169495582581\n",
      "0.6359555125236511 -0.5360857248306274\n",
      "0.6447378396987915 -0.5286920666694641\n",
      "0.6570308804512024 -0.5269415378570557\n",
      "0.6617182493209839 -0.5225664973258972\n",
      "0.6931498050689697 -0.5417845845222473\n",
      "0.6300826668739319 -0.5370113253593445\n",
      "0.6456549167633057 -0.5305416584014893\n",
      "0.6731466054916382 -0.5309554934501648\n",
      "0.741987407207489 -0.5276588201522827\n",
      "0.6626405715942383 -0.5295464396476746\n",
      "0.6626161336898804 -0.5158662796020508\n",
      "0.630591869354248 -0.5281506180763245\n",
      "0.6628745794296265 -0.5325638651847839\n",
      "0.6162539124488831 -0.5374575853347778\n",
      "0.6759454607963562 -0.5372446179389954\n",
      "0.6926043629646301 -0.5005515217781067\n",
      "0.6668906807899475 -0.5096054077148438\n",
      "0.6729701161384583 -0.5110777616500854\n",
      "0.13009612262248993 -0.529833197593689\n",
      "0.15721963346004486 -0.5000408291816711\n",
      "0.5260416865348816 -0.5121389031410217\n",
      "0.5953390002250671 -0.5449130535125732\n",
      "0.5643466711044312 -0.5303781628608704\n",
      "0.6193815469741821 -0.5046175122261047\n",
      "0.6110137104988098 -0.5441277623176575\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.7104598879814148 -0.5106198787689209\n",
      "0.7025536298751831 -0.5247825384140015\n",
      "0.6888514757156372 -0.5257276296615601\n",
      "0.6747632622718811 -0.5262954235076904\n",
      "0.701931357383728 -0.521800696849823\n",
      "0.6617205739021301 -0.5451359748840332\n",
      "0.6444653868675232 -0.5429295897483826\n",
      "0.5539565086364746 -0.5403964519500732\n",
      "0.28495916724205017 -0.5648970603942871\n",
      "0.6736915111541748 -0.5352327823638916\n",
      "0.6562331914901733 -0.5574870705604553\n",
      "0.612772524356842 -0.5403609275817871\n",
      "0.6172450184822083 -0.5322697758674622\n",
      "0.6387092471122742 -0.5621331334114075\n",
      "0.621442437171936 -0.564647376537323\n",
      "0.6444134712219238 -0.5597468614578247\n",
      "0.6311482787132263 -0.5521147847175598\n",
      "0.30923715233802795 -0.5361882448196411\n",
      "0.5512213706970215 -0.5357491374015808\n",
      "0.691421627998352 -0.5307316184043884\n",
      "0.0552837997674942 -0.5515992045402527\n",
      "0.5037401914596558 -0.5353484749794006\n",
      "0.5773868560791016 -0.5468413233757019\n",
      "0.4979598820209503 -0.5310891270637512\n",
      "0.3928922712802887 -0.5294777154922485\n",
      "0.07421358674764633 -0.5495269298553467\n",
      "-0.3486297130584717 -0.5152095556259155\n",
      "-0.5894736051559448 -0.5733598470687866\n",
      "0.3167174756526947 -0.5166022181510925\n",
      "0.6809069514274597 -0.5252029299736023\n",
      "0.5902521014213562 -0.5524834990501404\n",
      "0.619077742099762 -0.5538539290428162\n",
      "0.2558157742023468 -0.5391467213630676\n",
      "-0.036820486187934875 -0.5209737420082092\n",
      "0.07591328769922256 -0.5158026218414307\n",
      "0.625909686088562 -0.530737042427063\n",
      "0.6425759196281433 -0.5366441011428833\n",
      "0.6681511402130127 -0.5200446844100952\n",
      "0.05816015601158142 -0.5170215964317322\n",
      "0.5499329566955566 -0.5115297436714172\n",
      "0.5608327984809875 -0.5449717044830322\n",
      "0.173379585146904 -0.5414901971817017\n",
      "0.11308515816926956 -0.5511264204978943\n",
      "0.5713828802108765 -0.5310418605804443\n",
      "0.6297826766967773 -0.5422871708869934\n",
      "0.6416033506393433 -0.5173038244247437\n",
      "0.6614694595336914 -0.5331177711486816\n",
      "0.6747056841850281 -0.5425552129745483\n",
      "0.7085577249526978 -0.5188819766044617\n",
      "0.6814677119255066 -0.535457968711853\n",
      "0.6426547169685364 -0.5339419841766357\n",
      "0.6714164614677429 -0.5167114734649658\n",
      "0.6533085107803345 -0.5211284160614014\n",
      "0.634888768196106 -0.5309916138648987\n",
      "0.746452271938324 -0.49683696031570435\n",
      "0.6880595684051514 -0.5236763954162598\n",
      "0.22053490579128265 -0.5321601033210754\n",
      "-0.47930893301963806 -0.5514670014381409\n",
      "0.5510646104812622 -0.5226378440856934\n",
      "0.3042900562286377 -0.5311071276664734\n",
      "0.7001090049743652 -0.4887332320213318\n",
      "0.6773359179496765 -0.5170459151268005\n",
      "0.6713840365409851 -0.506058394908905\n",
      "0.49086081981658936 -0.5354518890380859\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.6638088226318359 -0.5094563364982605\n",
      "0.6786409020423889 -0.5419301986694336\n",
      "0.6247687935829163 -0.5420743823051453\n",
      "0.6090313792228699 -0.5432910323143005\n",
      "0.32888439297676086 -0.537386953830719\n",
      "0.026626821607351303 -0.5070181488990784\n",
      "0.6395714282989502 -0.48965662717819214\n",
      "0.6783818602561951 -0.4928237795829773\n",
      "0.7090612053871155 -0.5010765790939331\n",
      "0.6682248711585999 -0.5227810740470886\n",
      "0.670494019985199 -0.511218249797821\n",
      "0.6657145619392395 -0.5260381102561951\n",
      "0.502472460269928 -0.5181553363800049\n",
      "0.3170827627182007 -0.49615538120269775\n",
      "0.6741488575935364 -0.5199418067932129\n",
      "0.4204685091972351 -0.5458452701568604\n",
      "-0.1681600660085678 -0.5367524027824402\n",
      "0.560768723487854 -0.49989330768585205\n",
      "0.64495849609375 -0.514930009841919\n",
      "0.655035674571991 -0.5037757754325867\n",
      "0.6508327126502991 -0.5308022499084473\n",
      "0.6358274221420288 -0.5297998785972595\n",
      "0.5914492011070251 -0.517993152141571\n",
      "0.4028353691101074 -0.5253552198410034\n",
      "-0.5583580732345581 -0.5292023420333862\n",
      "0.4335048496723175 -0.5404313802719116\n",
      "0.3244621157646179 -0.5265294909477234\n",
      "0.43219152092933655 -0.5605486631393433\n",
      "0.5487348437309265 -0.5539301037788391\n",
      "0.6913624405860901 -0.5279366374015808\n",
      "0.6294733881950378 -0.5245711803436279\n",
      "0.6339437365531921 -0.5440335869789124\n",
      "0.6237162947654724 -0.5482572317123413\n",
      "0.6369300484657288 -0.534089207649231\n",
      "0.30185800790786743 -0.5432167053222656\n",
      "0.6420381665229797 -0.5346761345863342\n",
      "0.553531289100647 -0.4954623579978943\n",
      "0.5812826752662659 -0.4838527739048004\n",
      "0.5801962018013 -0.5076262950897217\n",
      "0.6613749265670776 -0.5203329920768738\n",
      "0.6620281338691711 -0.526907205581665\n",
      "0.5574847459793091 -0.5238462090492249\n",
      "0.6382692456245422 -0.5213682651519775\n",
      "0.09237824380397797 -0.5640453100204468\n",
      "0.27377307415008545 -0.5546702742576599\n",
      "0.618864893913269 -0.5386356115341187\n",
      "-0.055783238261938095 -0.5525480508804321\n",
      "0.5959199666976929 -0.5021279454231262\n",
      "0.6057718396186829 -0.5187808275222778\n",
      "0.04286135733127594 -0.5253050923347473\n",
      "0.623475193977356 -0.5355157256126404\n",
      "0.13925379514694214 -0.5760608315467834\n",
      "0.3218924105167389 -0.5266163349151611\n",
      "0.6121920347213745 -0.5079522132873535\n",
      "0.4883207678794861 -0.5180373191833496\n",
      "-0.48501017689704895 -0.5212838053703308\n",
      "0.5737771987915039 -0.5286775827407837\n",
      "-0.40289655327796936 -0.5392513871192932\n",
      "-0.03433290496468544 -0.5387568473815918\n",
      "0.6350460648536682 -0.5322161316871643\n",
      "0.34112486243247986 -0.5042821764945984\n",
      "0.049478549510240555 -0.5146995782852173\n",
      "-0.07049842178821564 -0.5598220825195312\n",
      "0.5393258333206177 -0.5376753807067871\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.364112913608551 -0.5262356400489807\n",
      "0.6017739772796631 -0.5321236848831177\n",
      "0.6875419616699219 -0.5062467455863953\n",
      "0.7110813856124878 -0.48584049940109253\n",
      "0.681403398513794 -0.5129645466804504\n",
      "0.6287857890129089 -0.5218390226364136\n",
      "0.630627453327179 -0.5110049247741699\n",
      "0.694004476070404 -0.4933721721172333\n",
      "0.6766434907913208 -0.5239222049713135\n",
      "0.6468052864074707 -0.5204257965087891\n",
      "0.5306437015533447 -0.5286633372306824\n",
      "0.2527656853199005 -0.5478653907775879\n",
      "0.40619683265686035 -0.5317260026931763\n",
      "0.6933717131614685 -0.5275629162788391\n",
      "0.6977500319480896 -0.5398238897323608\n",
      "0.6334491968154907 -0.5349912643432617\n",
      "0.6545664668083191 -0.5244450569152832\n",
      "0.6643005013465881 -0.5042511820793152\n",
      "0.6666532754898071 -0.5294500589370728\n",
      "0.6533876657485962 -0.5261327624320984\n",
      "0.6716502904891968 -0.5546991229057312\n",
      "0.6569658517837524 -0.5631591081619263\n",
      "0.6424438953399658 -0.567547082901001\n",
      "0.23325225710868835 -0.5473223328590393\n",
      "0.5124052166938782 -0.5368092060089111\n",
      "0.6482385993003845 -0.5281869173049927\n",
      "0.6544411182403564 -0.5487743020057678\n",
      "0.6359841227531433 -0.557573676109314\n",
      "0.023978352546691895 -0.528339147567749\n",
      "0.5195753574371338 -0.5379419922828674\n",
      "0.6627493500709534 -0.5401214361190796\n",
      "0.5581521391868591 -0.5314920544624329\n",
      "0.2775612473487854 -0.5495834350585938\n",
      "0.3271197974681854 -0.5410116910934448\n",
      "0.6405048370361328 -0.5424985885620117\n",
      "0.6775298714637756 -0.529420793056488\n",
      "0.7058379650115967 -0.5223831534385681\n",
      "0.6816213130950928 -0.5137947201728821\n",
      "0.645851194858551 -0.5293740630149841\n",
      "0.6340983510017395 -0.5247060656547546\n",
      "0.6861353516578674 -0.5362203121185303\n",
      "0.29104769229888916 -0.5503023266792297\n",
      "0.43341687321662903 -0.5475308299064636\n",
      "0.6689764857292175 -0.5177565217018127\n",
      "0.624931275844574 -0.5149505734443665\n",
      "0.6986325979232788 -0.5031158328056335\n",
      "0.6612251996994019 -0.5435953736305237\n",
      "0.602223813533783 -0.5288299918174744\n",
      "0.6497149467468262 -0.5488725304603577\n",
      "0.5701510310173035 -0.5558983683586121\n",
      "0.6314370632171631 -0.546360433101654\n",
      "0.5605145692825317 -0.5289448499679565\n",
      "0.6484474539756775 -0.5309525728225708\n",
      "0.634168803691864 -0.5234257578849792\n",
      "0.6493744850158691 -0.5367123484611511\n",
      "0.6737375855445862 -0.5299970507621765\n",
      "0.6326724290847778 -0.5622525811195374\n",
      "0.6496468782424927 -0.5306954383850098\n",
      "-0.13273783028125763 -0.5459629893302917\n",
      "0.6773207783699036 -0.5377199649810791\n",
      "0.6730495095252991 -0.5719394683837891\n",
      "0.6659204363822937 -0.5691869258880615\n",
      "0.6450231075286865 -0.56228107213974\n",
      "0.6041162014007568 -0.541739284992218\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.374146431684494 -0.546106219291687\n",
      "0.11270570009946823 -0.5036677718162537\n",
      "-0.057248204946517944 -0.5420318245887756\n",
      "-0.5267723202705383 -0.5367981791496277\n",
      "0.6243973970413208 -0.5159833431243896\n",
      "0.6537575721740723 -0.5359810590744019\n",
      "0.7100251317024231 -0.5228176712989807\n",
      "0.6788590550422668 -0.5287563800811768\n",
      "0.2864459455013275 -0.5484480261802673\n",
      "0.3938543200492859 -0.5478952527046204\n",
      "0.6594224572181702 -0.5314577221870422\n",
      "0.6508169174194336 -0.5489938855171204\n",
      "0.6671830415725708 -0.5498399138450623\n",
      "0.6661508083343506 -0.5561586618423462\n",
      "0.6667019128799438 -0.5532845854759216\n",
      "0.6763562560081482 -0.546465277671814\n",
      "0.6826064586639404 -0.5528493523597717\n",
      "0.45351162552833557 -0.5691052079200745\n",
      "-0.39326736330986023 -0.5758092999458313\n",
      "0.6690081357955933 -0.5652807950973511\n",
      "0.6981939077377319 -0.5556222200393677\n",
      "0.6691142320632935 -0.5577654242515564\n",
      "0.63654625415802 -0.5789957046508789\n",
      "0.651932418346405 -0.5835270881652832\n",
      "0.6857480406761169 -0.5706552267074585\n",
      "0.6843913793563843 -0.5548245310783386\n",
      "0.6716610193252563 -0.543919026851654\n",
      "0.6578546762466431 -0.5490357279777527\n",
      "0.6264635324478149 -0.5577376484870911\n",
      "0.69072026014328 -0.5429210066795349\n",
      "0.705750584602356 -0.5414513945579529\n",
      "0.6729748845100403 -0.5669568777084351\n",
      "0.6747782230377197 -0.5620255470275879\n",
      "0.6801013946533203 -0.5731680393218994\n",
      "0.6704975366592407 -0.5658250451087952\n",
      "0.6670183539390564 -0.5436862707138062\n",
      "-0.11158517003059387 -0.5666773319244385\n",
      "0.5120823979377747 -0.5463152527809143\n",
      "0.651458203792572 -0.5610882043838501\n",
      "0.693377673625946 -0.5383865237236023\n",
      "0.6529485583305359 -0.5527262091636658\n",
      "0.630898654460907 -0.534684419631958\n",
      "0.5975036025047302 -0.5359803438186646\n",
      "0.6630968451499939 -0.5366355776786804\n",
      "0.4109675884246826 -0.5371981859207153\n",
      "0.6420533657073975 -0.534770667552948\n",
      "0.6374617218971252 -0.5406520366668701\n",
      "0.5457866191864014 -0.5383909940719604\n",
      "0.6165172457695007 -0.5399230718612671\n",
      "0.6086544990539551 -0.5457932353019714\n",
      "0.6443120837211609 -0.529690682888031\n",
      "0.6879507899284363 -0.5151669979095459\n",
      "0.5793524384498596 -0.523144006729126\n",
      "0.6463196277618408 -0.5400953888893127\n",
      "0.6868097186088562 -0.5320844650268555\n",
      "0.6587345600128174 -0.5650706887245178\n",
      "0.6674135327339172 -0.5624126195907593\n",
      "0.6216049790382385 -0.5533816814422607\n",
      "0.6144217848777771 -0.5589207410812378\n",
      "0.6573164463043213 -0.5522215366363525\n",
      "0.6578890085220337 -0.5533015727996826\n",
      "0.6837795972824097 -0.5218374133110046\n",
      "0.6838343739509583 -0.5252617001533508\n",
      "0.666130781173706 -0.5252525210380554\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "-0.14986859261989594 -0.5392066240310669\n",
      "0.6874468326568604 -0.5286266803741455\n",
      "0.686775803565979 -0.5320094227790833\n",
      "0.6959682703018188 -0.5166614651679993\n",
      "0.6723071336746216 -0.5387053489685059\n",
      "0.669521689414978 -0.5459868311882019\n",
      "0.6546812057495117 -0.5667539238929749\n",
      "0.6691136956214905 -0.5379710793495178\n",
      "0.6669565439224243 -0.5300067067146301\n",
      "-0.10588593035936356 -0.556039035320282\n",
      "0.51849764585495 -0.5421509742736816\n",
      "0.6764745712280273 -0.5369315147399902\n",
      "0.6631080508232117 -0.546463668346405\n",
      "0.40901675820350647 -0.5877819657325745\n",
      "0.21890978515148163 -0.546989917755127\n",
      "0.6312897801399231 -0.52484130859375\n",
      "0.6396426558494568 -0.5277078747749329\n",
      "0.6356038451194763 -0.5417374968528748\n",
      "0.7170476317405701 -0.5278806686401367\n",
      "0.6370255947113037 -0.5684966444969177\n",
      "0.6538105607032776 -0.5542398691177368\n",
      "0.5379561185836792 -0.5298415422439575\n",
      "0.6599451303482056 -0.5653188228607178\n",
      "0.6727323532104492 -0.543084979057312\n",
      "0.6798067688941956 -0.5381947159767151\n",
      "0.6846107840538025 -0.564081072807312\n",
      "0.6734022498130798 -0.559953510761261\n",
      "0.6576111316680908 -0.5720672011375427\n",
      "0.6822900772094727 -0.5528122782707214\n",
      "0.6786675453186035 -0.5518845319747925\n",
      "0.6729046106338501 -0.5448735356330872\n",
      "0.6346129775047302 -0.5507394075393677\n",
      "0.6274310350418091 -0.5651779770851135\n",
      "0.6391311287879944 -0.5604942440986633\n",
      "0.6591506600379944 -0.5586930513381958\n",
      "0.6650486588478088 -0.5539225339889526\n",
      "0.6375018358230591 -0.5650302171707153\n",
      "0.6594268083572388 -0.5539395213127136\n",
      "0.6665646433830261 -0.5577952861785889\n",
      "0.6530593037605286 -0.5444014668464661\n",
      "0.6429622769355774 -0.5469655990600586\n",
      "0.6560692191123962 -0.5400235056877136\n",
      "0.6838846206665039 -0.5421273112297058\n",
      "0.6602249145507812 -0.5659627914428711\n",
      "0.6453104019165039 -0.541148841381073\n",
      "0.6462663412094116 -0.5389872193336487\n",
      "0.5688155293464661 -0.5213373303413391\n",
      "0.6668881773948669 -0.5388256907463074\n",
      "0.6731687784194946 -0.5198997259140015\n",
      "0.6463116407394409 -0.5075415372848511\n",
      "0.7158427238464355 -0.5312792062759399\n",
      "0.5940006971359253 -0.5269412398338318\n",
      "0.6261826753616333 -0.5126183032989502\n",
      "0.675605297088623 -0.5152300000190735\n",
      "0.3895682096481323 -0.5233153104782104\n",
      "0.7538840174674988 -0.5362963080406189\n",
      "-0.3360631763935089 -0.5510616898536682\n",
      "0.6638340950012207 -0.5607154369354248\n",
      "0.6291112899780273 -0.5533862709999084\n",
      "0.660138726234436 -0.5507109761238098\n",
      "0.6201099157333374 -0.5349855422973633\n",
      "0.6346268653869629 -0.5103617906570435\n",
      "0.5932381749153137 -0.5596010684967041\n",
      "0.6390770673751831 -0.572413980960846\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.45968830585479736 -0.516875147819519\n",
      "0.6673014760017395 -0.5056053400039673\n",
      "0.6835626363754272 -0.5317600965499878\n",
      "0.6942666172981262 -0.5248590707778931\n",
      "0.6447122097015381 -0.528163492679596\n",
      "0.665313720703125 -0.526652991771698\n",
      "0.6984800696372986 -0.5167137980461121\n",
      "0.7006865739822388 -0.5435068607330322\n",
      "0.6861892938613892 -0.5367826819419861\n",
      "0.6825639605522156 -0.5164948105812073\n",
      "0.6814054846763611 -0.5363259315490723\n",
      "0.680544376373291 -0.547088623046875\n",
      "0.6981544494628906 -0.539225161075592\n",
      "0.651399552822113 -0.5338818430900574\n",
      "0.644008994102478 -0.5230985879898071\n",
      "0.6811610460281372 -0.5499434471130371\n",
      "0.6886217594146729 -0.5552939176559448\n",
      "0.6825119853019714 -0.5633640289306641\n",
      "0.6721540689468384 -0.5449833273887634\n",
      "0.6985900402069092 -0.5274890661239624\n",
      "0.6314136981964111 -0.5458409190177917\n",
      "0.6836372017860413 -0.5417834520339966\n",
      "0.6941109895706177 -0.53769850730896\n",
      "0.6882312893867493 -0.563549816608429\n",
      "0.6932286024093628 -0.5341855883598328\n",
      "0.6993345618247986 -0.5462923645973206\n",
      "0.68096923828125 -0.5303551554679871\n",
      "0.6693363189697266 -0.5387540459632874\n",
      "0.6922897100448608 -0.5188232064247131\n",
      "0.6906648278236389 -0.5388211011886597\n",
      "0.6757619976997375 -0.5399292707443237\n",
      "0.6575648784637451 -0.5241142511367798\n",
      "0.6758769154548645 -0.5402304530143738\n",
      "0.6600177884101868 -0.5496425628662109\n",
      "0.6788405776023865 -0.5578526258468628\n",
      "0.6552891135215759 -0.5392323136329651\n",
      "0.6495025157928467 -0.5299491286277771\n",
      "0.6367254853248596 -0.5271177291870117\n",
      "0.641200065612793 -0.5459641218185425\n",
      "0.6815475821495056 -0.542718768119812\n",
      "0.6945300102233887 -0.5684109330177307\n",
      "0.692825198173523 -0.5480307340621948\n",
      "0.6739187836647034 -0.5567716956138611\n",
      "0.7058843970298767 -0.5357338786125183\n",
      "0.7094023823738098 -0.5279958844184875\n",
      "0.23021726310253143 -0.5664333701133728\n",
      "0.6756410598754883 -0.5254386067390442\n",
      "0.31334370374679565 -0.5447184443473816\n",
      "0.5196582674980164 -0.537876546382904\n",
      "0.6683511734008789 -0.4839989244937897\n",
      "0.6723591685295105 -0.5355327725410461\n",
      "0.6700510382652283 -0.5391317009925842\n",
      "0.6688271760940552 -0.5168811678886414\n",
      "0.6994759440422058 -0.5459060668945312\n",
      "0.6894049048423767 -0.5303667187690735\n",
      "0.6968275308609009 -0.49161621928215027\n",
      "0.6694512963294983 -0.5056813955307007\n",
      "0.649832010269165 -0.5336589813232422\n",
      "0.693236768245697 -0.5425723791122437\n",
      "0.6679375767707825 -0.5425077676773071\n",
      "0.45602649450302124 -0.5337567925453186\n",
      "0.05131329596042633 -0.51726895570755\n",
      "0.6515322327613831 -0.5043745040893555\n",
      "0.5728254914283752 -0.5547879934310913\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.6282671689987183 -0.5391359925270081\n",
      "0.6458060145378113 -0.554454505443573\n",
      "0.6797230839729309 -0.5567960739135742\n",
      "0.6899376511573792 -0.5383570194244385\n",
      "0.6859399676322937 -0.5285434126853943\n",
      "0.6895966529846191 -0.5498114228248596\n",
      "0.6713350415229797 -0.5521469712257385\n",
      "0.6466693878173828 -0.5326910018920898\n",
      "0.6136099696159363 -0.5664500594139099\n",
      "0.3704524636268616 -0.5480185747146606\n",
      "0.6616952419281006 -0.5288289785385132\n",
      "0.48642498254776 -0.49696317315101624\n",
      "0.45071977376937866 -0.5014086365699768\n",
      "0.5333771109580994 -0.5322704911231995\n",
      "0.6816543340682983 -0.5229940414428711\n",
      "0.6580196022987366 -0.5228970050811768\n",
      "0.6519516706466675 -0.5535206198692322\n",
      "0.623701810836792 -0.5459492802619934\n",
      "0.6237318515777588 -0.5414503812789917\n",
      "0.6484280824661255 -0.523833155632019\n",
      "0.566716194152832 -0.516694188117981\n",
      "0.2532714605331421 -0.558530330657959\n",
      "0.0818760022521019 -0.5322889089584351\n",
      "0.5819511413574219 -0.5218166708946228\n",
      "0.6603941321372986 -0.5406897664070129\n",
      "0.3467312753200531 -0.5562513470649719\n",
      "0.17510829865932465 -0.5330454707145691\n",
      "0.6796507835388184 -0.5189731121063232\n",
      "0.6608883142471313 -0.5539271831512451\n",
      "0.6480947136878967 -0.5582412481307983\n",
      "0.6753921508789062 -0.5512697696685791\n",
      "0.6329599618911743 -0.5466781854629517\n",
      "0.5304259061813354 -0.5626682639122009\n",
      "-0.3752404451370239 -0.5715356469154358\n",
      "0.6431612372398376 -0.5351463556289673\n",
      "0.6110334396362305 -0.5412240028381348\n",
      "0.5981385707855225 -0.5642849206924438\n",
      "0.6486648321151733 -0.5547523498535156\n",
      "0.5304076671600342 -0.5526885986328125\n",
      "0.6409080028533936 -0.5750682950019836\n",
      "0.6665917038917542 -0.5679401159286499\n",
      "0.7013528347015381 -0.543821394443512\n",
      "0.6439639329910278 -0.5733376741409302\n",
      "0.6103960871696472 -0.5528103709220886\n",
      "0.5823239684104919 -0.5406584143638611\n",
      "0.5964363813400269 -0.5549578070640564\n",
      "0.6528599262237549 -0.5649756193161011\n",
      "0.6488961577415466 -0.5697349905967712\n",
      "0.11667580902576447 -0.5554612278938293\n",
      "0.16984286904335022 -0.5701791048049927\n",
      "0.3929625153541565 -0.5789932012557983\n",
      "0.6629911065101624 -0.535488486289978\n",
      "0.6404285430908203 -0.5281862616539001\n",
      "0.6544997692108154 -0.5586017370223999\n",
      "0.6273061633110046 -0.5372361540794373\n",
      "0.6398309469223022 -0.5434536337852478\n",
      "0.6188889145851135 -0.5477733016014099\n",
      "0.6144611835479736 -0.5426868200302124\n",
      "0.6588129997253418 -0.5397406816482544\n",
      "0.6468112468719482 -0.5313028693199158\n",
      "0.66218501329422 -0.5453057289123535\n",
      "0.6376170516014099 -0.5376895666122437\n",
      "0.6677371859550476 -0.5487493276596069\n",
      "0.6643911600112915 -0.542983889579773\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([20, 896, 4608])\n",
      "0.5895677804946899 -0.5408214926719666\n",
      "0.29229074716567993 -0.5432482361793518\n",
      "-0.31944119930267334 -0.5538485646247864\n",
      "0.7054663896560669 -0.5182593464851379\n",
      "0.6687477231025696 -0.5288451313972473\n",
      "-0.23910747468471527 -0.5279075503349304\n",
      "0.259406179189682 -0.5237886905670166\n",
      "0.5448253750801086 -0.52323979139328\n",
      "0.6154143810272217 -0.5103434920310974\n",
      "0.6077728271484375 -0.570052981376648\n",
      "0.603917121887207 -0.555594265460968\n",
      "0.6180675029754639 -0.5308169722557068\n",
      "0.6154320240020752 -0.5482802987098694\n",
      "0.6116758584976196 -0.4977727234363556\n",
      "0.16527056694030762 -0.5486581325531006\n",
      "0.5707815885543823 -0.5355713963508606\n",
      "0.6188029050827026 -0.5371693968772888\n",
      "0.6115283966064453 -0.5144391655921936\n",
      "0.6066844463348389 -0.5090292096138\n",
      "0.1403234601020813 -0.5345894694328308\n",
      "-0.09131533652544022 -0.5455493330955505\n",
      "0.6547976136207581 -0.52569180727005\n",
      "0.5325815081596375 -0.5544212460517883\n",
      "0.2207822948694229 -0.5601352453231812\n",
      "0.6333657503128052 -0.5313283205032349\n",
      "0.6541252732276917 -0.5489724278450012\n",
      "0.6174687743186951 -0.5190306305885315\n",
      "0.6260979175567627 -0.5422894954681396\n",
      "0.6024391055107117 -0.5557580590248108\n",
      "0.6137032508850098 -0.5437350869178772\n",
      "0.614124596118927 -0.5453070998191833\n",
      "0.6157042980194092 -0.5260763764381409\n",
      "-0.6936807632446289 -0.5532885193824768\n",
      "0.10206315666437149 -0.5382792949676514\n",
      "0.14191125333309174 -0.556801974773407\n",
      "0.6021283268928528 -0.5299044251441956\n",
      "0.6019399762153625 -0.5290286540985107\n",
      "0.2381759136915207 -0.5276572108268738\n",
      "-0.79686039686203 -0.5205416679382324\n",
      "0.2174500823020935 -0.5298058986663818\n",
      "0.6006705164909363 -0.5204248428344727\n",
      "0.6634151339530945 -0.5133436918258667\n",
      "0.6348012089729309 -0.5547091364860535\n",
      "0.6631726622581482 -0.5523107647895813\n",
      "0.6150953769683838 -0.5295335054397583\n",
      "0.5979856252670288 -0.5654705762863159\n",
      "0.6503069996833801 -0.5406681895256042\n",
      "0.6497089266777039 -0.5380407571792603\n",
      "0.4210754632949829 -0.5399999618530273\n",
      "0.174037903547287 -0.5155084729194641\n",
      "0.5608494281768799 -0.5390443205833435\n",
      "0.15199683606624603 -0.5440589785575867\n",
      "0.1030348464846611 -0.5420894622802734\n",
      "0.18490122258663177 -0.5650184750556946\n",
      "0.5990062355995178 -0.5064961314201355\n",
      "-0.22625300288200378 -0.5350338816642761\n",
      "0.46870195865631104 -0.5534411668777466\n",
      "0.4705544710159302 -0.5363211631774902\n",
      "0.6618193984031677 -0.5457728505134583\n",
      "0.6903911828994751 -0.5358101725578308\n",
      "0.48815658688545227 -0.5502557158470154\n",
      "0.6906290650367737 -0.5377377271652222\n",
      "0.6327603459358215 -0.5315201282501221\n",
      "-0.1092027947306633 -0.5261144638061523\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/mnt/nfs_dna/DNALM/downstream_tasks/enformer/human/h5/human_train.h5\"\n",
    "train_dataset = EnformerDataset(tokenizer, data_path)\n",
    "\n",
    "print(f'len(train_dataset): {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=20, num_workers=5, collate_fn=collate_fn)\n",
    "\n",
    "mem_acc.get_module().eval()\n",
    "predictor.train()\n",
    "\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {\"params\": predictor.parameters(), \"lr\": 5e-5},\n",
    "] , weight_decay=1e-5)\n",
    "\n",
    "for it, batch in enumerate(train_dataloader):\n",
    "\n",
    "    if it > 10:\n",
    "        break\n",
    "    \n",
    "    info = {}\n",
    "    done = False\n",
    "    print()\n",
    "    state = torch.zeros(batch[\"center\"][\"labels\"].shape[0], 200, model_cfg.hidden_size, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "    train_set = []\n",
    "    train_state = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        context_collector, last_state, _, _ = memup_iter_acc.forward(batch, state, {}, ContextCollector())\n",
    "        train_state = last_state\n",
    "        context = torch.cat(context_collector.collection, 1)\n",
    "        print(\"context\", context.shape)\n",
    "        if context.shape[1] != 896:\n",
    "            continue\n",
    "\n",
    "    last_state = last_state.cuda()\n",
    "    for j in range(0, 896, 14):\n",
    "        optimizer.zero_grad()\n",
    "        pred_j = predictor(context[:, j:j+14].cuda(), last_state)\n",
    "        tg_j = batch[\"center\"][\"labels\"][:, j:j+14].cuda()\n",
    "        loss = nn.PoissonNLLLoss(log_input=False)(pred_j, tg_j)\n",
    "        pc = PearsonCorrLoss()(pred_j.reshape(-1, 5313), tg_j.reshape(-1, 5313)).item()\n",
    "        print(loss.item(), pc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_acc.accumulate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 1937\n",
      "\n",
      "stage left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buzun/filtered-transformer/.conda/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.48307672142982483\n",
      "simple_corr_coef -0.5330652594566345\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.49964195489883423\n",
      "simple_corr_coef -0.5433982014656067\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.50095534324646\n",
      "simple_corr_coef -0.5415904919306437\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.5036499500274658\n",
      "simple_corr_coef -0.5358397215604782\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.5023065209388733\n",
      "simple_corr_coef -0.5389904141426086\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4914115071296692\n",
      "simple_corr_coef -0.53477015097936\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4960555136203766\n",
      "simple_corr_coef -0.5365365828786578\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4934762716293335\n",
      "simple_corr_coef -0.5374034345149994\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.492843359708786\n",
      "simple_corr_coef -0.5381459328863356\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.49691012501716614\n",
      "simple_corr_coef -0.537880539894104\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.49436670541763306\n",
      "simple_corr_coef -0.5380060239271685\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.49312224984169006\n",
      "simple_corr_coef -0.5373386243979136\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4914981722831726\n",
      "simple_corr_coef -0.5373319020638099\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4937553107738495\n",
      "simple_corr_coef -0.5371167404311044\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4912073612213135\n",
      "simple_corr_coef -0.5364987810452779\n",
      "\n",
      "stage left\n",
      "stage center\n",
      "stage right\n",
      "context torch.Size([30, 896, 4608])\n",
      "torch.Size([30, 896, 5313])\n",
      "pearson_corr_coef 0.4903275668621063\n",
      "simple_corr_coef -0.5366839803755283\n",
      "\n",
      "stage left\n",
      "stage center\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb Ячейка 3\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.18.20/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m train_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.18.20/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.18.20/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     context_collector, last_state, _, _ \u001b[39m=\u001b[39m memup_iter_acc\u001b[39m.\u001b[39;49mforward(batch, state, {}, ContextCollector())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.18.20/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     train_state \u001b[39m=\u001b[39m last_state\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.18.20/home/buzun/filtered-transformer/examples/enformer_2/Untitled-1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(context_collector\u001b[39m.\u001b[39mcollection, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/filtered-transformer/memup/base.py:132\u001b[0m, in \u001b[0;36mMemoryRollout.forward\u001b[0;34m(self, data, state, info, collector, steps)\u001b[0m\n\u001b[1;32m    129\u001b[0m         info \u001b[39m=\u001b[39m update\u001b[39m.\u001b[39mforward(data, state, info)\n\u001b[1;32m    131\u001b[0m filtered_data, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_filter(data, state, info)\n\u001b[0;32m--> 132\u001b[0m out, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49mforward(filtered_data, state)\n\u001b[1;32m    133\u001b[0m collector\u001b[39m.\u001b[39mappend(filtered_data, out, state)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/filtered-transformer/examples/enformer_2/modules.py:182\u001b[0m, in \u001b[0;36mMemUpMemoryImpl.forward\u001b[0;34m(self, data, state)\u001b[0m\n\u001b[1;32m    178\u001b[0m     bins_count \u001b[39m=\u001b[39m bins_mask[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    179\u001b[0m     B, D \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], out\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    180\u001b[0m     bins_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\n\u001b[1;32m    181\u001b[0m         data[\u001b[39m\"\u001b[39m\u001b[39mpositions\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m--> 182\u001b[0m         hidden[bins_mask]\u001b[39m.\u001b[39mreshape(B, bins_count \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m, D \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m),\n\u001b[1;32m    183\u001b[0m         out[bins_mask]\u001b[39m.\u001b[39mreshape(B, bins_count \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, D \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m    184\u001b[0m     ], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    185\u001b[0m     \u001b[39mreturn\u001b[39;00m bins_output, new_state\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/filtered-transformer/.conda/lib/python3.10/site-packages/torch/_tensor.py:37\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f, assigned\u001b[39m=\u001b[39massigned)\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m         \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m             \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pearson_corr_coef = MeanPearsonCorrCoefPerChannel(5313)\n",
    "mem_acc.get_module().eval()\n",
    "pred_acc.get_module().eval()\n",
    "\n",
    "simple_corr = []\n",
    "\n",
    "data_path = \"/mnt/nfs_dna/DNALM/downstream_tasks/enformer/human/h5/human_test.h5\"\n",
    "train_dataset = EnformerDataset(tokenizer, data_path)\n",
    "\n",
    "print(f'len(train_dataset): {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=30, num_workers=5, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# optimizer = AdamW([\n",
    "#     {\"params\": predictor.parameters(), \"lr\": 5e-5},\n",
    "# ] , weight_decay=1e-5)\n",
    "\n",
    "for it, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    info = {}\n",
    "    done = False\n",
    "    print()\n",
    "    state = torch.zeros(batch[\"center\"][\"labels\"].shape[0], 200, model_cfg.hidden_size, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "    train_set = []\n",
    "    train_state = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        context_collector, last_state, _, _ = memup_iter_acc.forward(batch, state, {}, ContextCollector())\n",
    "        train_state = last_state\n",
    "        context = torch.cat(context_collector.collection, 1)\n",
    "        print(\"context\", context.shape)\n",
    "        if context.shape[1] != 896:\n",
    "            continue\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for j in range(0, 896, 14):\n",
    "            pred_j = pred_acc(context[:, j:j+14].cuda(), last_state.cuda()).cpu()\n",
    "            # tg_j = batch[\"center\"][\"labels\"][:, j:j+14]\n",
    "            predictions.append(pred_j)\n",
    "\n",
    "\n",
    "        predictions = torch.cat(predictions, 1)\n",
    "        print(predictions.shape)\n",
    "\n",
    "        pearson_corr_coef.update(predictions, batch[\"center\"][\"labels\"])\n",
    "        p_corr = pearson_corr_coef.compute().mean().item()\n",
    "        print(\"pearson_corr_coef\", p_corr)\n",
    "\n",
    "        simple_corr.append(PearsonCorrLoss()(predictions.reshape(-1, 5313), batch[\"center\"][\"labels\"].reshape(-1, 5313)).item())\n",
    "        print(\"simple_corr_coef\", sum(simple_corr) / len(simple_corr))\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b20f3d5c387d4ae708cf3b110b498b9508be8d8f3c9e0454b8d051d60f269555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
